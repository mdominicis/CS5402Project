{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht69R1PgsdM8",
    "outputId": "cf36a6d7-dd70-4444-88b1-f5240b1df3ec"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cluster        import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor # new\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejZRtYz3HBRE",
    "outputId": "91f8051c-486a-42c6-f2de-bfa1a1c97913"
   },
   "outputs": [],
   "source": [
    "file_path = \"vehiclesclean.csv\"\n",
    "if os.path.isfile(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    df = kagglehub.load_dataset(\n",
    "      KaggleDatasetAdapter.PANDAS,\n",
    "      \"austinreese/craigslist-carstrucks-data\",\n",
    "      file_path\n",
    "    )\n",
    "    df = df.drop(columns=['id', 'region', 'url', 'region_url', 'VIN', 'image_url', 'description', 'county', 'lat', 'long', 'posting_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BE88secND8yN"
   },
   "outputs": [],
   "source": [
    "# print(len(df)) 426880 rows before dropping\n",
    "df = df.dropna()\n",
    "# print(len(df)) 79195 after dropping\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "categorical_columns = []\n",
    "features = df.columns.values.tolist()\n",
    "\n",
    "# Find categorical features\n",
    "for col in features:\n",
    "    if df[col].dtype in numerics: continue\n",
    "    categorical_columns.append(col)\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df[col].astype(str).values))\n",
    "        df[col] = le.transform(list(df[col].astype(str).values))\n",
    "\n",
    "# Only use cars from last 15 years\n",
    "df['year'] = (2025-df['year']).astype(int)\n",
    "df = df[df['year'] < 15]\n",
    "\n",
    "# Only using cars priced from 1-100k\n",
    "df = df[df['price'] > 1000]\n",
    "df = df[df['price'] < 150000]\n",
    "\n",
    "# Binning odometer into groups of 5k\n",
    "df['odometer'] = df['odometer'].astype(int)\n",
    "df['odometer'] = df['odometer'] // 5000\n",
    "\n",
    "\n",
    "def make_desc(row):\n",
    "    return (\n",
    "        f\"This is a {row['condition']} {int(row['year'])} {row['manufacturer']} {row['model']}, \"\n",
    "        f\"a {row['size']} sized {row['type']} with a {int(row['cylinders'])}-cylinder {row['fuel']} engine, \"\n",
    "        f\"{row['transmission']} transmission, and {row['drive']} drive. \"\n",
    "        f\"It has {int(row['odometer']):,} miles, holds a {row['title_status']} title in {row['state']}, \"\n",
    "        f\"is painted {row['paint_color']}, predict its price.\"\n",
    "    )\n",
    "\n",
    "df['description'] = df.apply(make_desc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, X_test, y_train, y_test): # Linear Regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), y_pred\n",
    "\n",
    "def PR(X_train, X_test, y_train, y_test): # Polynomial Regression\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    pr = LinearRegression()\n",
    "    pr.fit(X_train_poly, y_train)\n",
    "\n",
    "    y_pred = pr.predict(X_test_poly)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), y_pred\n",
    "\n",
    "def RF(X_train, X_test, y_train, y_test): # Random Forest\n",
    "    rf = RandomForestRegressor(\n",
    "        random_state=0\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), y_pred\n",
    "\n",
    "def NN(X_train, X_test, y_train, y_test): # Neural Network\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "    cluster_train = kmeans.fit_predict(X_train)\n",
    "    cluster_test  = kmeans.predict(X_test)\n",
    "\n",
    "    X_train_aug = np.hstack([X_train, cluster_train.reshape(-1,1)])\n",
    "    X_test_aug  = np.hstack([X_test,  cluster_test.reshape( -1,1)])\n",
    "\n",
    "    nn = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=0)\n",
    "    nn.fit(X_train_aug, y_train)\n",
    "\n",
    "    y_pred = nn.predict(X_test_aug)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['description', 'price'], axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "lr_r2, lr_mse, lr_yp = LR(X_train, X_test, y_train, y_test)\n",
    "pr_r2, pr_mse, pr_yp = PR(X_train, X_test, y_train, y_test)\n",
    "rf_r2, rf_mse, rf_yp = RF(X_train, X_test, y_train, y_test)\n",
    "nn_r2, nn_mse, nn_yp = NN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"dfbert.parquet\"\n",
    "if os.path.isfile(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    class TextDataset(Dataset):\n",
    "        def __init__(self, texts):\n",
    "            self.texts = texts\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            return self.texts[idx]\n",
    "\n",
    "    def process_batch(batch):\n",
    "        encoded = tokenizer(\n",
    "            batch,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "        \n",
    "        return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "    dataset = TextDataset(df['description'].tolist())\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "    for batch in dataloader:\n",
    "        embeddings.append(process_batch(batch))\n",
    "        \n",
    "    embeddings_matrix = np.vstack(embeddings)\n",
    "\n",
    "    pca = PCA(n_components=50, random_state=0)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings_matrix)\n",
    "\n",
    "    pca_cols  = [f'bert_pca_{i}'  for i in range(reduced_embeddings.shape[1])]\n",
    "    pca_df  = pd.DataFrame(reduced_embeddings, columns=pca_cols,  index=df.index)\n",
    "\n",
    "    df = pd.concat([df, pca_df], axis=1)\n",
    "    df.to_parquet('dfbert.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['description', 'price'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "blr_r2, blr_mse, blr_yp = LR(X_train, X_test, y_train, y_test)\n",
    "bpr_r2, bpr_mse, bpr_yp = PR(X_train, X_test, y_train, y_test)\n",
    "brf_r2, brf_mse, brf_yp = RF(X_train, X_test, y_train, y_test)\n",
    "bnn_r2, bnn_mse, bnn_yp = NN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Linear Regression\", \"Polynomial Regression\", \"Random Forest\", \"Neural Network\"]\n",
    "\n",
    "r2 = {\n",
    "    \"Standard\": [lr_r2, pr_r2, rf_r2, nn_r2],\n",
    "    \"BERT\":     [blr_r2, bpr_r2, brf_r2, bnn_r2]\n",
    "}\n",
    "\n",
    "mse = {\n",
    "    \"Standard\": [lr_mse, pr_mse, rf_mse, nn_mse],\n",
    "    \"BERT\":     [blr_mse, bpr_mse, brf_mse, bnn_mse]\n",
    "}\n",
    "\n",
    "y_pred = {\n",
    "    \"Standard\": [lr_yp, pr_yp, rf_yp, nn_yp],\n",
    "    \"BERT\":     [blr_yp, bpr_yp, brf_yp, bnn_yp]\n",
    "}\n",
    "\n",
    "def print_table(title, data, fmt):\n",
    "    print(title)\n",
    "    header = \" \" * 12 + \"\".join(f\"{m:<{30}}\" for m in models)\n",
    "    print(header)\n",
    "    print(\"-\" * (len(header) - 15))\n",
    "    for row_name, vals in data.items():\n",
    "        row = f\"{row_name:<12}\"\n",
    "        for v in vals:\n",
    "            spec = f\"<{30}{fmt}\"\n",
    "            row += format(v, spec)\n",
    "        print(row)\n",
    "    print()\n",
    "\n",
    "print_table(\"R-squared (R²)\", r2, \".4f\")\n",
    "print_table(\"Mean Squared Error (MSE)\", mse, \".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    std_pred  = y_pred[\"Standard\"][i]\n",
    "    bert_pred = y_pred[\"BERT\"][i]\n",
    "\n",
    "    ax.scatter(y_test, std_pred,  alpha=0.6, label='Standard', edgecolor='k', linewidth=0.2)\n",
    "    ax.scatter(y_test, bert_pred, alpha=0.6, label='BERT',     edgecolor='k', linewidth=0.2)\n",
    "\n",
    "    mn = min(y_test.min(),  std_pred.min(),  bert_pred.min())\n",
    "    mx = max(y_test.max(),  std_pred.max(),  bert_pred.max())\n",
    "    ax.plot([mn, mx], [mn, mx], '--')\n",
    "\n",
    "    ax.set_title(models[i])\n",
    "    ax.set_xlabel('Actual Price')\n",
    "    ax.set_ylabel('Predicted Price')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
