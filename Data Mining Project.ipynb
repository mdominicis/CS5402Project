{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht69R1PgsdM8",
    "outputId": "cf36a6d7-dd70-4444-88b1-f5240b1df3ec"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cluster        import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejZRtYz3HBRE",
    "outputId": "91f8051c-486a-42c6-f2de-bfa1a1c97913"
   },
   "outputs": [],
   "source": [
    "file_path = \"vehiclesclean.csv\"\n",
    "if os.path.isfile(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    df = kagglehub.load_dataset(\n",
    "      KaggleDatasetAdapter.PANDAS,\n",
    "      \"austinreese/craigslist-carstrucks-data\",\n",
    "      file_path\n",
    "    )\n",
    "    df = df.drop(columns=['id', 'region', 'url', 'region_url', 'VIN', 'image_url', 'description', 'county', 'lat', 'long', 'posting_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BE88secND8yN"
   },
   "outputs": [],
   "source": [
    "# print(len(df)) 426880 rows before dropping\n",
    "df = df.dropna()\n",
    "# print(len(df)) 79195 after dropping\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "categorical_columns = []\n",
    "features = df.columns.values.tolist()\n",
    "\n",
    "# Find categorical features\n",
    "for col in features:\n",
    "    if df[col].dtype in numerics: continue\n",
    "    categorical_columns.append(col)\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df[col].astype(str).values))\n",
    "        df[col] = le.transform(list(df[col].astype(str).values))\n",
    "\n",
    "# Only use cars from last 15 years\n",
    "df['year'] = (2025-df['year']).astype(int)\n",
    "df = df[df['year'] < 15]\n",
    "\n",
    "# Only using cars priced from 1-100k\n",
    "df = df[df['price'] > 1000]\n",
    "df = df[df['price'] < 150000]\n",
    "\n",
    "# Binning odometer into groups of 5k\n",
    "df['odometer'] = df['odometer'].astype(int)\n",
    "df['odometer'] = df['odometer'] // 5000\n",
    "\n",
    "\n",
    "def make_desc(row):\n",
    "    return (\n",
    "        f\"This is a {row['condition']} {int(row['year'])} {row['manufacturer']} {row['model']}, \"\n",
    "        f\"a {row['size']} sized {row['type']} with a {int(row['cylinders'])}-cylinder {row['fuel']} engine, \"\n",
    "        f\"{row['transmission']} transmission, and {row['drive']} drive. \"\n",
    "        f\"It has {int(row['odometer']):,} miles, holds a {row['title_status']} title in {row['state']}, \"\n",
    "        f\"is painted {row['paint_color']}, predict its price.\"\n",
    "    )\n",
    "\n",
    "df['description'] = df.apply(make_desc, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "# Batch processing function\n",
    "def process_batch(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "dataset = TextDataset(df['description'].tolist())\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Process all batches\n",
    "embeddings = []\n",
    "for batch in dataloader:\n",
    "    embeddings.append(process_batch(batch))\n",
    "    \n",
    "embeddings_matrix = np.vstack(embeddings)\n",
    "\n",
    "# Add to DataFrame\n",
    "for i in range(embeddings_matrix.shape[1]):\n",
    "    df[f'bert_{i}'] = embeddings_matrix[:, i]\n",
    "\n",
    "# Dimensionality reduction\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_matrix)\n",
    "for i in range(reduced_embeddings.shape[1]):\n",
    "    df[f'bert_pca_{i}'] = reduced_embeddings[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['description', 'price'], axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTT6v0amGwya"
   },
   "source": [
    "### Matthew's Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r50nxc7AGwiC",
    "outputId": "14c2e8ac-62fc-49b7-8b50-29ce3e425f18"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "lr_r2 = r2_score(y_test, y_pred)\n",
    "lr_mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feNx_QTbHHyz"
   },
   "source": [
    "### Logan's Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oK3O7kIPOU3T",
    "outputId": "730d9891-642e-4029-b805-02c8cc8d476a"
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "pr_r2 = r2_score(y_test, y_pred)\n",
    "pr_mse = mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9nPDHtWF05v"
   },
   "source": [
    "### Dheeraj's Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xxk7eF_0F0JD",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "dt_r2 = r2_score(y_test, y_pred)\n",
    "dt_mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrSjEjT1QHOz"
   },
   "source": [
    "### Everett's Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYCoRK5xQOtN"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "nn_r2 = r2_score(y_test, y_pred)\n",
    "nn_mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"R-squared (RÂ²): \\n\\tLinear Regression: {lr_r2:.4f}\\n\\tPolynomial Regression: {pr_r2:.4f}\\n\\tDecision Tree: {dt_r2:.4f}\\n\\tNeural Network: {nn_r2:.4f}\")\n",
    "print()\n",
    "print(f\"Mean Squared Error (MSE): \\n\\tLinear Regression: {lr_mse:.2f}\\n\\tPolynomial Regression: {pr_mse:.2f}\\n\\tDecision Tree: {dt_mse:.2f}\\n\\tNeural Network: {nn_mse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
