{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht69R1PgsdM8",
    "outputId": "cf36a6d7-dd70-4444-88b1-f5240b1df3ec"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cluster        import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejZRtYz3HBRE",
    "outputId": "91f8051c-486a-42c6-f2de-bfa1a1c97913"
   },
   "outputs": [],
   "source": [
    "file_path = \"vehiclesclean.csv\"\n",
    "if os.path.isfile(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    df = kagglehub.load_dataset(\n",
    "      KaggleDatasetAdapter.PANDAS,\n",
    "      \"austinreese/craigslist-carstrucks-data\",\n",
    "      file_path\n",
    "    )\n",
    "    df = df.drop(columns=['id', 'region', 'url', 'region_url', 'VIN', 'image_url', 'description', 'county', 'lat', 'long', 'posting_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BE88secND8yN"
   },
   "outputs": [],
   "source": [
    "# print(len(df)) 426880 rows before dropping\n",
    "df = df.dropna()\n",
    "# print(len(df)) 79195 after dropping\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "categorical_columns = []\n",
    "features = df.columns.values.tolist()\n",
    "\n",
    "# Find categorical features\n",
    "for col in features:\n",
    "    if df[col].dtype in numerics: continue\n",
    "    categorical_columns.append(col)\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df[col].astype(str).values))\n",
    "        df[col] = le.transform(list(df[col].astype(str).values))\n",
    "\n",
    "# Only use cars from last 15 years\n",
    "df['year'] = (2025-df['year']).astype(int)\n",
    "df = df[df['year'] < 15]\n",
    "\n",
    "# Only using cars priced from 1-100k\n",
    "df = df[df['price'] > 1000]\n",
    "df = df[df['price'] < 150000]\n",
    "\n",
    "# Binning odometer into groups of 5k\n",
    "df['odometer'] = df['odometer'].astype(int)\n",
    "df['odometer'] = df['odometer'] // 5000\n",
    "\n",
    "\n",
    "def make_desc(row):\n",
    "    return (\n",
    "        f\"This is a {row['condition']} {int(row['year'])} {row['manufacturer']} {row['model']}, \"\n",
    "        f\"a {row['size']} sized {row['type']} with a {int(row['cylinders'])}-cylinder {row['fuel']} engine, \"\n",
    "        f\"{row['transmission']} transmission, and {row['drive']} drive. \"\n",
    "        f\"It has {int(row['odometer']):,} miles, holds a {row['title_status']} title in {row['state']}, \"\n",
    "        f\"is painted {row['paint_color']}, predict its price.\"\n",
    "    )\n",
    "\n",
    "df['description'] = df.apply(make_desc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, X_test, y_train, y_test): # Linear Regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred)\n",
    "\n",
    "def PR(X_train, X_test, y_train, y_test): # Polynomial Regression\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred)\n",
    "\n",
    "def DT(X_train, X_test, y_train, y_test): # Decision Tree\n",
    "    model = DecisionTreeRegressor(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred)\n",
    "\n",
    "def NN(X_train, X_test, y_train, y_test): # Neural Network\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "    cluster_train = kmeans.fit_predict(X_train)\n",
    "    cluster_test  = kmeans.predict(X_test)\n",
    "\n",
    "    X_train_aug = np.hstack([X_train, cluster_train.reshape(-1,1)])\n",
    "    X_test_aug  = np.hstack([X_test,  cluster_test.reshape( -1,1)])\n",
    "\n",
    "    model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=0)\n",
    "    model.fit(X_train_aug, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_aug)\n",
    "\n",
    "    return r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['description', 'price'], axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "lr_r2, lr_mse = LR(X_train, X_test, y_train, y_test)\n",
    "pr_r2, pr_mse = PR(X_train, X_test, y_train, y_test)\n",
    "dt_r2, dt_mse = DT(X_train, X_test, y_train, y_test)\n",
    "nn_r2, nn_mse = NN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"dfbert.parquet\"\n",
    "if os.path.isfile(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    class TextDataset(Dataset):\n",
    "        def __init__(self, texts):\n",
    "            self.texts = texts\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            return self.texts[idx]\n",
    "\n",
    "    def process_batch(batch):\n",
    "        encoded = tokenizer(\n",
    "            batch,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "        \n",
    "        return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "    dataset = TextDataset(df['description'].tolist())\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "    for batch in dataloader:\n",
    "        embeddings.append(process_batch(batch))\n",
    "        \n",
    "    embeddings_matrix = np.vstack(embeddings)\n",
    "\n",
    "    pca = PCA(n_components=50, random_state=0)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings_matrix)\n",
    "\n",
    "    pca_cols  = [f'bert_pca_{i}'  for i in range(reduced_embeddings.shape[1])]\n",
    "    pca_df  = pd.DataFrame(reduced_embeddings, columns=pca_cols,  index=df.index)\n",
    "\n",
    "    df = pd.concat([df, pca_df], axis=1)\n",
    "    df.to_parquet('dfbert.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['description', 'price'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "blr_r2, blr_mse = LR(X_train, X_test, y_train, y_test)\n",
    "bpr_r2, bpr_mse = PR(X_train, X_test, y_train, y_test)\n",
    "bdt_r2, bdt_mse = DT(X_train, X_test, y_train, y_test)\n",
    "bnn_r2, bnn_mse = NN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard\")\n",
    "print(f\"R-squared (R²): \\n\\tLinear Regression: {lr_r2:.4f}\\n\\tPolynomial Regression: {pr_r2:.4f}\\n\\tDecision Tree: {dt_r2:.4f}\\n\\tNeural Network: {nn_r2:.4f}\")\n",
    "print()\n",
    "print(f\"Mean Squared Error (MSE): \\n\\tLinear Regression: {lr_mse:.2f}\\n\\tPolynomial Regression: {pr_mse:.2f}\\n\\tDecision Tree: {dt_mse:.2f}\\n\\tNeural Network: {nn_mse:.2f}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"BERT\")\n",
    "print(f\"R-squared (R²): \\n\\tLinear Regression: {blr_r2:.4f}\\n\\tPolynomial Regression: {bpr_r2:.4f}\\n\\tDecision Tree: {bdt_r2:.4f}\\n\\tNeural Network: {bnn_r2:.4f}\")\n",
    "print()\n",
    "print(f\"Mean Squared Error (MSE): \\n\\tLinear Regression: {blr_mse:.2f}\\n\\tPolynomial Regression: {bpr_mse:.2f}\\n\\tDecision Tree: {bdt_mse:.2f}\\n\\tNeural Network: {bnn_mse:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
